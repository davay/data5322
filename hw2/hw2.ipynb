{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebd8143435acaf",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac1fb38",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d33929af9ac250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:06:44.058903Z",
     "start_time": "2024-04-29T06:06:43.998931Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-29T06:07:09.758910Z",
     "start_time": "2024-04-29T06:07:09.752112Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retrieve labels from https://usa.ipums.org/usa-action/variables/live_search for exploration purposes\n",
    "col_labels = {\n",
    "    \"SERIAL\": \"Household serial number\",\n",
    "    \"DENSITY\": \"Population-weighted density of PUMA\",  # PUMA is Public Use Microdata Area\n",
    "    \"OWNERSHP\": \"Ownership of dwelling (tenure) [general version]\",  # owned/being bought vs rented\n",
    "    \"OWNERSHPD\": \"Ownership of dwelling (tenure) [detailed version]\",  # e.g. rented vs no cash rent vs cash rent\n",
    "    \"COSTELEC\": \"Annual electricity cost\",\n",
    "    \"COSTGAS\": \"Annual gas cost\",\n",
    "    \"COSTWATR\": \"Annual water cost\",\n",
    "    \"COSTFUEL\": \"Annual home heating fuel cost\",\n",
    "    \"HHINCOME\": \"Total household income\",\n",
    "    \"VALUEH\": \"House value\",\n",
    "    \"ROOMS\": \"Number of rooms\",\n",
    "    \"BUILTYR2\": \"Age of structure, decade\",\n",
    "    \"BEDROOMS\": \"Number of bedrooms\",\n",
    "    \"VEHICLES\": \"Vehicles available\",\n",
    "    \"NFAMS\": \"Number of families in household\",\n",
    "    \"NCOUPLES\": \"Number of couples in household\",\n",
    "    \"PERNUM\": \"Person number in sample unit\",\n",
    "    \"PERWT\": \"Person weight\",  # sampling weight, indicates how many persons in the U.S. population are represented by a given person\n",
    "    \"AGE\": \"Age\",\n",
    "    \"MARST\": \"Marital status\",\n",
    "    \"BIRTHYR\": \"Year of birth\",\n",
    "    \"EDUC\": \"Educational attainment [general version]\",\n",
    "    \"EDUCD\": \"Educational attainment [detailed version]\",\n",
    "    \"INCTOT\": \"Total personal income\",\n",
    "}\n",
    "\n",
    "df_readable = df.rename(columns=col_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2716715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by columns of interest and replace special missing values with NaN\n",
    "cols_of_interest = [\n",
    "    \"Household serial number\",\n",
    "    \"Population-weighted density of PUMA\",\n",
    "    \"Ownership of dwelling (tenure) [general version]\",\n",
    "    \"Number of rooms\",\n",
    "    \"Age of structure, decade\",\n",
    "    \"Number of bedrooms\",\n",
    "    \"Number of families in household\",\n",
    "    \"Number of couples in household\",\n",
    "    \"Age\",\n",
    "    \"Marital status\",\n",
    "    \"Educational attainment [general version]\",\n",
    "    \"Total personal income\",\n",
    "]\n",
    "\n",
    "missing_values_per_col = {\n",
    "    \"Total personal income\": [9999999],\n",
    "}\n",
    "\n",
    "df_filtered = df_readable[cols_of_interest].replace(missing_values_per_col, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d99e159a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename some long column names\n",
    "cols_rename_map = {\n",
    "    \"Population-weighted density of PUMA\": \"Population-weighted density\",\n",
    "    \"Ownership of dwelling (tenure) [general version]\": \"Ownership of dwelling\",\n",
    "    \"Educational attainment [general version]\": \"Educational attainment\",\n",
    "}\n",
    "\n",
    "df_filtered = df_filtered.rename(columns=cols_rename_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0b99dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 11840 rows with missing values out of 68131 (17.38%)\n"
     ]
    }
   ],
   "source": [
    "# filter to single family households with 0 or 1 couples -- 2 or 3 couples of the same family living in the same household is an outlier.\n",
    "df_single_family = df_filtered[\n",
    "    (df_filtered[\"Number of families in household\"] == 1)\n",
    "    & (\n",
    "        (df_filtered[\"Number of couples in household\"] == 1)\n",
    "        | (df_filtered[\"Number of couples in household\"] == 0)\n",
    "    )\n",
    "]\n",
    "\n",
    "# remove all rows with missing values\n",
    "initial_length = len(df_single_family)\n",
    "df_single_family = df_single_family.dropna()\n",
    "new_length = len(df_single_family)\n",
    "rows_dropped = initial_length - new_length\n",
    "print(f\"Removed {rows_dropped} rows with missing values out of {initial_length} ({(rows_dropped / initial_length)*100:.2f}%)\")\n",
    "\n",
    "# aggregate per head of household, defined as a person 18 or older with highest personal income\n",
    "index = (\n",
    "    df_single_family[df_single_family[\"Age\"] >= 18]\n",
    "    .groupby(\"Household serial number\")[\"Total personal income\"]\n",
    "    .idxmax()\n",
    ")\n",
    "df_single_family = df_single_family.loc[index]\n",
    "\n",
    "# we can also aggregate by sorting, but seems like a bad approach\n",
    "# df_single_family = df_single_family.sort_values(\"Total personal income\", ascending=False).drop_duplicates(\"Household serial number\")\n",
    "\n",
    "# drop Number of families in household since it's always 1\n",
    "# drop Household serial number since we've already aggregated, and it's not useful as a predictor\n",
    "df_single_family = df_single_family.drop(columns=[\"Number of families in household\", \"Household serial number\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f965c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group education into 5 categories: less than high school, high school, some college, bachelor's, graduate\n",
    "# by default is (], left-exclusive and right-inclusive\n",
    "bins = [0, 5, 6, 9, 10, 11]\n",
    "labels = [\n",
    "    \"Less than high school\",\n",
    "    \"High school\",\n",
    "    \"Some college\",\n",
    "    \"Bachelor's\",\n",
    "    \"Graduate\",\n",
    "]\n",
    "df_single_family[\"Educational attainment\"] = pd.cut(\n",
    "    df_single_family[\"Educational attainment\"],\n",
    "    bins=bins,\n",
    "    labels=labels,\n",
    "    include_lowest=True,  # so 0 is included in 0-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a1114c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group marital status into 3 categories: married (spouse present/absent), previously married (separated/divorced/widowed), never married\n",
    "bins = [1, 2, 5, 6]\n",
    "labels = [\n",
    "    \"Married\",\n",
    "    \"Previously married\",\n",
    "    \"Never married\",\n",
    "]\n",
    "df_single_family[\"Marital status\"] = pd.cut(\n",
    "    df_single_family[\"Marital status\"],\n",
    "    bins=bins,\n",
    "    labels=labels,\n",
    "    include_lowest=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beacb10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename ownership of dwelling categories, 1 is Owned or being bought, 2 is Rented\n",
    "df_single_family = df_single_family.replace(\n",
    "    {\"Ownership of dwelling\": {1: \"Owned\", 2: \"Rented\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "557442da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical predictors as nominal, the distance betweeen our categories is hard to quantify and may not be equal\n",
    "# e.g. would distance between \"Less than high school\" and \"High school\" be the same as \"High school\" and \"Some college\"?\n",
    "nominal_cols = [\n",
    "    \"Educational attainment\",\n",
    "    \"Marital status\",\n",
    "]\n",
    "\n",
    "# one-hot encode (which is different to dummy encode) - doesn't drop first category, easier to interpret and SVM can handle it\n",
    "df_onehot = pd.get_dummies(df_single_family[nominal_cols], drop_first=False)\n",
    "df_single_family = pd.concat([df_single_family, df_onehot], axis=1)\n",
    "df_single_family = df_single_family.drop(columns=nominal_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f87ad04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group age into 3 categories: 18-34 (young adults), 35-64 (middle-aged adults), 65+ (older adults)\n",
    "bins = [18, 34, 64, float('inf')]\n",
    "labels = [\"Young adults\", \"Middle-aged adults\", \"Older adults\"]\n",
    "# keep age as original data for later\n",
    "age_groups = pd.cut(\n",
    "    df_single_family[\"Age\"],\n",
    "    bins=bins,\n",
    "    labels=labels,\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "# create 3 separate dataframes for each age group\n",
    "df_young_adults = df_single_family[age_groups == \"Young adults\"]\n",
    "df_middle_aged_adults = df_single_family[age_groups == \"Middle-aged adults\"]\n",
    "df_older_adults = df_single_family[age_groups == \"Older adults\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cbb4e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler for later use \n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9334ec84",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189dba71",
   "metadata": {},
   "source": [
    "### Young Adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43b50d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_young_adults.drop(columns=['Ownership of dwelling'])\n",
    "y = df_young_adults['Ownership of dwelling']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e405f",
   "metadata": {},
   "source": [
    "#### Radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5670bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Radial CV results: C=1, gamma=0.01\n",
      "Train error: 0.2017412188531973\n",
      "Test error: 0.20028011204481788\n"
     ]
    }
   ],
   "source": [
    "svm_rbf = SVC(kernel=\"rbf\", tol=0.1)\n",
    "\n",
    "kFold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "params = {\"C\": [0.001, 0.01, 0.1, 1], \"gamma\": [0.0001, 0.001, 0.01, 1, 10, 100]}\n",
    "cv = GridSearchCV(\n",
    "    svm_rbf,\n",
    "    param_grid=params,\n",
    "    cv=kFold,\n",
    "    refit=True,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    verbose=1,\n",
    ")\n",
    "cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "train_accuracy = cv.best_estimator_.score(X_train_scaled, y_train)\n",
    "train_error = 1 - train_accuracy\n",
    "test_accuracy = cv.best_estimator_.score(X_test_scaled, y_test)\n",
    "test_error = 1 - test_accuracy\n",
    "\n",
    "best_C_rbf = cv.best_params_[\"C\"]\n",
    "best_gamma = cv.best_params_[\"gamma\"]\n",
    "print(f\"Radial CV results: C={best_C_rbf}, gamma={best_gamma}\")\n",
    "print(\"Train error:\", train_error)\n",
    "print(\"Test error:\", test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c0d6a8",
   "metadata": {},
   "source": [
    "#### Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f9f8591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 396 candidates, totalling 1980 fits\n"
     ]
    }
   ],
   "source": [
    "svm_poly = SVC(kernel=\"poly\", tol=0.1)\n",
    "\n",
    "kFold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "params = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1],\n",
    "    \"degree\": np.arange(2, 11, 1),\n",
    "    \"coef0\": np.arange(0, 11, 1),\n",
    "}\n",
    "cv = GridSearchCV(\n",
    "    svm_poly,\n",
    "    param_grid=params,\n",
    "    cv=kFold,\n",
    "    refit=True,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    verbose=1,\n",
    ")\n",
    "cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "train_accuracy = cv.best_estimator_.score(X_train_scaled, y_train)\n",
    "train_error = 1 - train_accuracy\n",
    "test_accuracy = cv.best_estimator_.score(X_test_scaled, y_test)\n",
    "test_error = 1 - test_accuracy\n",
    "\n",
    "best_C_poly = cv.best_params_[\"C\"]\n",
    "best_degree = cv.best_params_[\"degree\"]\n",
    "best_coef0 = cv.best_params_[\"coef0\"]\n",
    "\n",
    "print(f\"Poly CV results: C={best_C_poly}, degree={best_degree}, coef0={best_coef0}\")\n",
    "print(\"Train error:\", train_error)\n",
    "print(\"Test error:\", test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d231f2fa",
   "metadata": {},
   "source": [
    "#### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f1ad7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear = SVC(kernel=\"linear\", tol=0.1) \n",
    "\n",
    "kFold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "params = {\"C\": [0.001, 0.01, 0.1, 1]}\n",
    "cv = GridSearchCV(\n",
    "    svm_linear,\n",
    "    param_grid=params,\n",
    "    cv=kFold,\n",
    "    refit=True,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    verbose=1,\n",
    ")\n",
    "cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "train_accuracy = cv.best_estimator_.score(X_train_scaled, y_train)\n",
    "train_error = 1 - train_accuracy\n",
    "test_accuracy = cv.best_estimator_.score(X_test_scaled, y_test)\n",
    "test_error = 1 - test_accuracy\n",
    "\n",
    "best_C_linear = cv.best_params_[\"C\"]\n",
    "\n",
    "print(f\"Linear CV results: C={best_C_linear}\")\n",
    "print(\"Train error:\", train_error)\n",
    "print(\"Test error:\", test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737d7242",
   "metadata": {},
   "source": [
    "### Middle-Aged Adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c09455",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_middle_aged_adults.drop(columns=['Ownership of dwelling'])\n",
    "y = df_middle_aged_adults['Ownership of dwelling']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf7b7be",
   "metadata": {},
   "source": [
    "#### Radial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b2a252",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf = SVC(kernel=\"rbf\", tol=0.1)\n",
    "\n",
    "kFold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "params = {\"C\": [0.001, 0.01, 0.1, 1, 10], \"gamma\": [0.0001, 0.001, 0.01, 1, 10, 100]}\n",
    "cv = GridSearchCV(\n",
    "    svm_rbf,\n",
    "    param_grid=params,\n",
    "    cv=kFold,\n",
    "    refit=True,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    verbose=1,\n",
    ")\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = cv.best_estimator_.score(X_train, y_train)\n",
    "train_error = 1 - train_accuracy\n",
    "test_accuracy = cv.best_estimator_.score(X_test, y_test)\n",
    "test_error = 1 - test_accuracy\n",
    "\n",
    "best_C_rbf = cv.best_params_[\"C\"]\n",
    "best_gamma = cv.best_params_[\"gamma\"]\n",
    "print(f\"Radial CV results: C={best_C_rbf}, gamma={best_gamma}\")\n",
    "print(\"Train error:\", train_error)\n",
    "print(\"Test error:\", test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f13d19",
   "metadata": {},
   "source": [
    "#### Poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8611687",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly = SVC(kernel=\"poly\", tol=0.1)\n",
    "\n",
    "kFold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "params = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"degree\": np.arange(2, 6, 1),\n",
    "    \"coef0\": np.arange(0, 11, 1),\n",
    "}\n",
    "cv = GridSearchCV(\n",
    "    svm_poly,\n",
    "    param_grid=params,\n",
    "    cv=kFold,\n",
    "    refit=True,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    verbose=1,\n",
    ")\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = cv.best_estimator_.score(X_train, y_train)\n",
    "train_error = 1 - train_accuracy\n",
    "test_accuracy = cv.best_estimator_.score(X_test, y_test)\n",
    "test_error = 1 - test_accuracy\n",
    "\n",
    "best_C_poly = cv.best_params_[\"C\"]\n",
    "best_degree = cv.best_params_[\"degree\"]\n",
    "best_coef0 = cv.best_params_[\"coef0\"]\n",
    "\n",
    "print(f\"Poly CV results: C={best_C_poly}, degree={best_degree}, coef0={best_coef0}\")\n",
    "print(\"Train error:\", train_error)\n",
    "print(\"Test error:\", test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fcea07",
   "metadata": {},
   "source": [
    "#### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d29779",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear = SVC(kernel=\"linear\", tol=0.1)  # default is 0.001 but it's very slow\n",
    "\n",
    "kFold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "params = {\"C\": [0.001, 0.01, 0.1, 1, 10]}\n",
    "cv = GridSearchCV(\n",
    "    svm_linear,\n",
    "    param_grid=params,\n",
    "    cv=kFold,\n",
    "    refit=True,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"accuracy\",\n",
    "    verbose=1,\n",
    ")\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "train_accuracy = cv.best_estimator_.score(X_train, y_train)\n",
    "train_error = 1 - train_accuracy\n",
    "test_accuracy = cv.best_estimator_.score(X_test, y_test)\n",
    "test_error = 1 - test_accuracy\n",
    "\n",
    "best_C_linear = cv.best_params_[\"C\"]\n",
    "\n",
    "print(f\"Linear CV results: C={best_C_linear}\")\n",
    "print(\"Train error:\", train_error)\n",
    "print(\"Test error:\", test_error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
